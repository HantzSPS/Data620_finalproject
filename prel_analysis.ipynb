{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "WordNet is the lexical database i.e. dictionary for the English language,  specifically designed for natural language processing. And lemma is wordnet's version of an entry in a dictionary.  The following analysis will allow us to identify some characteristics of each speech.  We will get the number of words used, the average length of sentence in the speech and unique word used in the speech.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#Import libraries\n",
    "\n",
    "import glob\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wordnet_tag(tag):\n",
    "\n",
    "  if tag.startswith('JJ'):\n",
    "\n",
    "    return 'a'\n",
    "\n",
    "  elif tag.startswith('RB') or tag == \"WRB\":\n",
    "\n",
    "    return 'r'\n",
    "\n",
    "  elif tag.startswith('NN') or tag.startswith(\"WP\"):\n",
    "\n",
    "    return 'n'\n",
    "\n",
    "  elif tag.startswith('VB'):\n",
    "\n",
    "    return 'v'\n",
    "\n",
    "  else:\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# YYYY name num_sentences num_words avg_sentence_len num_unique_words num_unique_lemmas\n",
      "1789 \"George Washington\" 27 1580 58.518519 639 600\n",
      "1793 \"George Washington\" 6 177 29.500000 110 105\n",
      "1797 \"John Adams\" 39 2608 66.871795 833 768\n",
      "1801 \"Thomas Jefferson\" 43 1951 45.372093 724 684\n",
      "1805 \"Thomas Jefferson\" 47 2404 51.148936 814 739\n",
      "1809 \"James Madison\" 23 1287 55.956522 544 516\n",
      "1813 \"James Madison\" 35 1332 38.057143 552 520\n",
      "1817 \"James Monroe\" 123 3697 30.056911 1047 940\n",
      "1821 \"James Monroe\" 131 4905 37.442748 1268 1119\n",
      "1825 \"John Quincy Adams\" 76 3167 41.671053 1012 924\n",
      "1829 \"Andrew Jackson\" 27 1232 45.629630 528 509\n",
      "1833 \"Andrew Jackson\" 32 1290 40.312500 507 479\n",
      "1837 \"Martin Van Buren\" 97 4171 43.000000 1324 1187\n",
      "1841 \"William Henry Harrison\" 212 9113 42.985849 1919 1653\n",
      "1845 \"James K. Polk\" 155 5201 33.554839 1345 1204\n",
      "1849 \"Zachary Taylor\" 24 1206 50.250000 507 487\n",
      "1853 \"Franklin Pierce\" 106 3659 34.518868 1176 1084\n",
      "1857 \"James Buchanan\" 91 3107 34.142857 951 879\n",
      "1861 \"Abraham Lincoln\" 150 4265 28.433333 1159 1039\n",
      "1865 \"Abraham Lincoln\" 31 832 26.838710 382 367\n",
      "1869 \"Ulysses S. Grant\" 42 1248 29.714286 499 464\n",
      "1873 \"Ulysses S. Grant\" 45 1497 33.266667 561 508\n",
      "1877 \"Rutherford B. Hayes\" 61 2715 44.508197 850 778\n",
      "1881 \"James A. Garfield\" 114 3262 28.614035 1042 947\n",
      "1885 \"Grover Cleveland\" 46 1841 40.021739 682 637\n",
      "1889 \"Benjamin Harrison\" 159 4763 29.955975 1360 1221\n",
      "1893 \"Grover Cleveland\" 60 2165 36.083333 827 771\n",
      "1897 \"William McKinley\" 132 4371 33.113636 1244 1126\n",
      "1901 \"William McKinley\" 102 2474 24.254902 866 795\n",
      "1905 \"Theodore Roosevelt\" 35 1109 31.685714 415 392\n",
      "1909 \"William Howard Taft\" 161 5851 36.341615 1439 1258\n",
      "1913 \"Woodrow Wilson\" 70 1917 27.385714 668 615\n",
      "1917 \"Woodrow Wilson\" 61 1679 27.524590 559 516\n",
      "1921 \"Warren Harding\" 150 3759 25.060000 1174 1072\n",
      "1925 \"Calvin Coolidge\" 198 4470 22.575758 1228 1092\n",
      "1929 \"Herbert Hoover\" 166 4089 24.632530 1132 1025\n",
      "1933 \"Franklin Roosevelt\" 87 2108 24.229885 757 693\n",
      "1937 \"Franklin Roosevelt\" 98 2005 20.459184 736 683\n",
      "1941 \"Franklin Roosevelt\" 70 1508 21.542857 548 512\n",
      "1945 \"Franklin Roosevelt\" 28 638 22.785714 291 280\n",
      "1949 \"Harry S. Truman\" 118 2520 21.355932 791 727\n",
      "1953 \"Dwight Eisenhower\" 121 2758 22.793388 906 846\n",
      "1957 \"Dwight Eisenhower\" 94 1888 20.085106 633 592\n",
      "1961 \"John F. Kennedy\" 54 1544 28.592593 578 549\n",
      "1965 \"Lyndon Johnson\" 96 1705 17.760417 577 531\n",
      "1969 \"Richard Nixon\" 105 2412 22.971429 761 692\n",
      "1973 \"Richard Nixon\" 70 2003 28.614286 560 501\n",
      "1974 \"Gerald Ford\" 43 975 22.674419 410 392\n",
      "1977 \"Jimmy Carter\" 54 1395 25.833333 530 506\n",
      "1981 \"Ronald Reagan\" 129 2801 21.713178 911 830\n",
      "1985 \"Ronald Reagan\" 126 2928 23.238095 936 840\n",
      "1989 \"George H. W. Bush\" 145 2709 18.682759 801 720\n",
      "1993 \"Bill Clinton\" 95 1860 19.578947 642 583\n",
      "1997 \"Bill Clinton\" 114 2484 21.789474 780 713\n",
      "2001 \"George W. Bush\" 86 1859 21.616279 635 588\n",
      "2005 \"George W. Bush\" 99 2383 24.070707 778 695\n",
      "2009 \"Barack Obama\" 109 2643 24.247706 941 861\n",
      "2013 \"Barack Obama\" 85 2413 28.388235 820 762\n",
      "2017 \"Donald Trump\" 95 1714 18.042105 581 539\n"
     ]
    }
   ],
   "source": [
    "#Form a dictionary of speeches \n",
    "\n",
    "speeches = dict()\n",
    "\n",
    "for filename in glob.glob(\"Data/*.txt\"):\n",
    "\n",
    "  basename = os.path.basename(filename)\n",
    "\n",
    "  name     = os.path.splitext(basename)[0]\n",
    "\n",
    "  name     = name.replace(\"_\", \" \")\n",
    "\n",
    "  year     = name[:4]\n",
    "\n",
    "  name     = year+\"-\"+name[5:]\n",
    "\n",
    "  with open(filename, 'r', encoding='utf8') as f:\n",
    "\n",
    "    speech         = f.read()\n",
    "\n",
    "    speeches[name] = speech\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "num_sent     = dict()\n",
    "\n",
    "num_words         = dict()\n",
    "\n",
    "avg_sent_len  = dict()\n",
    "\n",
    "num_uniq_lemmas = dict() \n",
    "\n",
    "num_uniq_words  = dict()\n",
    "\n",
    "\n",
    "\n",
    "print(\"# YYYY name num_sentences num_words avg_sentence_len num_unique_words num_unique_lemmas\")\n",
    "\n",
    "\n",
    "\n",
    "for president in sorted(speeches.keys()):\n",
    "\n",
    "  speech    = speeches[president]\n",
    "\n",
    "  sentences = sent_tokenize(speech)\n",
    "\n",
    "  words     = word_tokenize(speech)\n",
    "\n",
    "\n",
    "\n",
    "  avg_sent_len[president]  = 0.0\n",
    "\n",
    "  for sentence in sentences:\n",
    "\n",
    "    avg_sent_len[president] += len(word_tokenize(sentence))\n",
    "\n",
    "  avg_sent_len[president] /= len(sentences)\n",
    "\n",
    "\n",
    "\n",
    "  num_sent[president]    = len(sentences)\n",
    "\n",
    "  num_words[president]        = len(words)\n",
    "\n",
    "  num_uniq_words[president] = len(set(words))\n",
    "\n",
    "\n",
    "\n",
    "  tagged = nltk.pos_tag(words)\n",
    "\n",
    "  lemmas  = set()\n",
    "\n",
    "\n",
    "\n",
    "  for word,tag in tagged:\n",
    "\n",
    "    pos = get_wordnet_tag(tag)\n",
    "\n",
    "    if pos:\n",
    "\n",
    "      lemmas.add(lemmatizer.lemmatize(word, pos=pos))\n",
    "\n",
    "    else:\n",
    "\n",
    "      lemmas.add(word)\n",
    "\n",
    "\n",
    "\n",
    "  year = int(president[:4])\n",
    "\n",
    "  name = president[5:]\n",
    "\n",
    "\n",
    "\n",
    "  num_uniq_lemmas[president] = len(lemmas)\n",
    "\n",
    "  print('%d \"%s\" %d %d %f %d %d' % (year, name, num_sent[president], num_words[president], avg_sent_len[president], num_uniq_words[president], num_uniq_lemmas[president] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are comparing the last 2 presidents we can notice that President Trump use more sentences that President Obama but Obama use more unique words and lemmas words than Trump.  The shortest speech is Georges Washington in 1793. It has only 6 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@ajgabriel_30288/sentiment-analysis-of-political-speeches-managing-unstructured-text-using-r-b090a42c0bf5  \n",
    "https://bastian.rieck.me/blog/posts/2017/inauguration_speeches_brief/  \n",
    "https://github.com/hunsnowboarder/sentiment_analyis_aws_cloud/blob/master/AWS_NLP.ipynb  \n",
    "https://github.com/Pseudomanifold/us-inauguration-speeches/tree/master/Data  \n",
    "https://bastian.rieck.me/blog/posts/2017/inauguration_speeches_sentiment_analysis/  \n",
    "https://www.dataquest.io/blog/web-scraping-beautifulsoup/  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
