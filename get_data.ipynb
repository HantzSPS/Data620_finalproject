{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#Importing libraries\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to get the name of each president from the title\n",
    "\n",
    "def getName(title):\n",
    "\n",
    "  i = title.index(\"'\")\n",
    "\n",
    "  n = title[:i]\n",
    "\n",
    "  n = n.replace(\" \", \"_\")\n",
    "  return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to get the speech from the wiki website using beautiful Soup\n",
    "def getSpeech(name, url):\n",
    "\n",
    "  page    = requests.get(url)\n",
    "\n",
    "  content = page.content\n",
    "\n",
    "  soup    = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "  header  = soup.find(\"div\", class_=\"gen_header_title\")\n",
    "\n",
    "  div     = soup.find(id=\"mw-content-text\")\n",
    "\n",
    "  year    = re.search(r'\\((\\d+)\\)', header.text).group(1)\n",
    "\n",
    "\n",
    "\n",
    "  # Remove all licence containers\n",
    "\n",
    "  licences = soup.find_all(\"div\", class_=\"licenseContainer licenxseBanner\")\n",
    "\n",
    "  for licence in licences:\n",
    "\n",
    "    licence.decompose()\n",
    "\n",
    "  \n",
    "\n",
    "  speech = \"\"\n",
    "\n",
    "  for p in div.find_all(\"p\", recursive=True):\n",
    "\n",
    "    speech += p.text + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "  return year,speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing John_Adams...\n",
      "Processing John_Quincy_Adams...\n",
      "Processing James_Buchanan...\n",
      "Processing George_H._W._Bush...\n",
      "Processing George_W._Bush...\n",
      "Processing George_W._Bush...\n",
      "Processing Jimmy_Carter...\n",
      "Processing Grover_Cleveland...\n",
      "Processing Grover_Cleveland...\n",
      "Processing Bill_Clinton...\n",
      "Processing Bill_Clinton...\n",
      "Processing Calvin_Coolidge...\n",
      "Processing Dwight_Eisenhower...\n",
      "Processing Dwight_Eisenhower...\n",
      "Processing Gerald_Ford...\n",
      "Processing James_A._Garfield...\n",
      "Processing Ulysses_S._Grant...\n",
      "Processing Ulysses_S._Grant...\n",
      "Processing Warren_Harding...\n",
      "Processing Benjamin_Harrison...\n",
      "Processing William_Henry_Harrison...\n",
      "Processing Rutherford_B._Hayes...\n",
      "Processing Herbert_Hoover...\n",
      "Processing Andrew_Jackson...\n",
      "Processing Andrew_Jackson...\n",
      "Processing Thomas_Jefferson...\n",
      "Processing Thomas_Jefferson...\n",
      "Processing Lyndon_Johnson...\n",
      "Processing John_F._Kennedy...\n",
      "Processing Abraham_Lincoln...\n",
      "Processing Abraham_Lincoln...\n",
      "Processing James_Madison...\n",
      "Processing James_Madison...\n",
      "Processing William_McKinley...\n",
      "Processing William_McKinley...\n",
      "Processing James_Monroe...\n",
      "Processing James_Monroe...\n",
      "Processing Richard_Nixon...\n",
      "Processing Richard_Nixon...\n",
      "Processing Barack_Obama...\n",
      "Processing Barack_Obama...\n",
      "Processing Franklin_Pierce...\n",
      "Processing James_K._Polk...\n",
      "Processing Ronald_Reagan...\n",
      "Processing Ronald_Reagan...\n",
      "Processing Franklin_Roosevelt...\n",
      "Processing Franklin_Roosevelt...\n",
      "Processing Franklin_Roosevelt...\n",
      "Processing Franklin_Roosevelt...\n",
      "Processing Theodore_Roosevelt...\n",
      "Processing William_Howard_Taft...\n",
      "Processing Zachary_Taylor...\n",
      "Processing Harry_S._Truman...\n",
      "Processing Donald_Trump...\n",
      "Processing Martin_Van_Buren...\n",
      "Processing George_Washington...\n",
      "Processing George_Washington...\n",
      "Processing Woodrow_Wilson...\n",
      "Processing Woodrow_Wilson...\n"
     ]
    }
   ],
   "source": [
    "#Write the text to a folder in the format of year_presidentname.txt\n",
    "overviewURL     = Using b\n",
    "baseURL         = urljoin(overviewURL, '/')\n",
    "\n",
    "overviewPage    = requests.get(overviewURL)\n",
    "\n",
    "overviewContent = overviewPage.content\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(overviewContent, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "for category in soup.find_all(\"div\", class_=\"mw-category-group\"):\n",
    "\n",
    "  ul = category.find(\"ul\")\n",
    "\n",
    "  for li in ul.find_all(\"li\"):\n",
    "\n",
    "    a    = li.find(\"a\")\n",
    "\n",
    "    page   = a['href']\n",
    "\n",
    "    name   = getName(a.text)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Processing %s...\" % name)\n",
    "\n",
    "\n",
    "\n",
    "    url          = urljoin(baseURL, page)\n",
    "\n",
    "    year, speech = getSpeech(name, url)\n",
    "    \n",
    "    #save_path= \n",
    "\n",
    "\n",
    "\n",
    "    with open(\"%s.txt\" % (year + \"_\" + name), \"w\", encoding=\"utf8\") as f:\n",
    "\n",
    "      f.write(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the inaugural speeches have been written into our data folder.  Next we will conduct a simplifed analysis with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@ajgabriel_30288/sentiment-analysis-of-political-speeches-managing-unstructured-text-using-r-b090a42c0bf5  \n",
    "https://bastian.rieck.me/blog/posts/2017/inauguration_speeches_brief/  \n",
    "https://github.com/hunsnowboarder/sentiment_analyis_aws_cloud/blob/master/AWS_NLP.ipynb  \n",
    "https://github.com/Pseudomanifold/us-inauguration-speeches/tree/master/Data  \n",
    "https://bastian.rieck.me/blog/posts/2017/inauguration_speeches_sentiment_analysis/  \n",
    "https://www.dataquest.io/blog/web-scraping-beautifulsoup/  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
